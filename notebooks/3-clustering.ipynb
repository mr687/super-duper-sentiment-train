{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering: Data Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import swifter\n",
    "\n",
    "from ast import literal_eval\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "indoset_lexicon_neg_path = '../dataset/wordlist/indoset_lexicon_neg.csv'\n",
    "indoset_lexicon_pos_path = '../dataset/wordlist/indoset_lexicon_pos.csv'\n",
    "vulgarity_lexicon_path = '../dataset/wordlist/vulgarity_lexicon.csv'\n",
    "\n",
    "target = 'tweets.csv'\n",
    "processed_target_path = f'../dataset/processed/processed_{target}'\n",
    "output_path = f'../dataset/processed/supervised_{target}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lexicon neg: 6609\n",
      "Total lexicon pos: 3609\n",
      "Total lexicon vulgarity: 62\n"
     ]
    }
   ],
   "source": [
    "indoset_lexicon_neg = pd.read_csv(indoset_lexicon_neg_path, delimiter='\\t')\n",
    "indoset_lexicon_pos = pd.read_csv(indoset_lexicon_pos_path, delimiter='\\t')\n",
    "vulgarity_lexicon = pd.read_csv(vulgarity_lexicon_path, header=None, delimiter='\\t')\n",
    "\n",
    "print(f\"Total lexicon neg:\", len(indoset_lexicon_neg))\n",
    "print(f\"Total lexicon pos:\", len(indoset_lexicon_pos))\n",
    "print(f\"Total lexicon vulgarity:\", len(vulgarity_lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10280\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>mengejek</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>penanganan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>cocok</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>berkarya</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>rasio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  weight\n",
       "4596    mengejek      -4\n",
       "1144  penanganan       1\n",
       "1406       cocok       4\n",
       "1036    berkarya       3\n",
       "745        rasio       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_dict = pd.concat([indoset_lexicon_pos, indoset_lexicon_neg], ignore_index=True)\n",
    "\n",
    "vulgarity_lexicon_weight = [-5 for word in vulgarity_lexicon[0]]\n",
    "vulgarity_lexicon = pd.DataFrame(list(zip(vulgarity_lexicon[0],vulgarity_lexicon_weight)),columns =['word','weight'])\n",
    "\n",
    "lexicon_dict = pd.concat([lexicon_dict, vulgarity_lexicon], ignore_index=True)\n",
    "print(len(lexicon_dict))\n",
    "lexicon_dict.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_folding(text):\n",
    "    return text.lower()\n",
    "    \n",
    "def num_of_words(item):\n",
    "    words = word_tokenize(item['word'])\n",
    "    number = len(words)\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b5cb9f385744179d4629807d242eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343cdbe2ab77495693e9eb121032580c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9109\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "      <th>num_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>berat pinggul</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>kaji</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6442</th>\n",
       "      <td>melanggar</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>tempoh</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>mengantisipasi</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  weight  num_of_words\n",
       "3974   berat pinggul      -2             2\n",
       "2076            kaji       4             1\n",
       "6442       melanggar      -5             1\n",
       "3062          tempoh       3             1\n",
       "166   mengantisipasi       3             1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_dict['word'] = lexicon_dict['word'].swifter.apply(case_folding)\n",
    "lexicon_dict['num_of_words'] = lexicon_dict.swifter.apply(num_of_words, axis=1)\n",
    "lexicon_dict = lexicon_dict.drop(lexicon_dict[lexicon_dict['num_of_words'] == 0].index, axis=0)\n",
    "lexicon_dict.drop_duplicates(subset=['word'], keep='first',inplace=True)\n",
    "lexicon_dict = lexicon_dict.reset_index(drop=True)\n",
    "\n",
    "print(len(lexicon_dict))\n",
    "lexicon_dict.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "      <th>num_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3607</th>\n",
       "      <td>putus tali gantung</td>\n",
       "      <td>-2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>jalan bebas hambat</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7468</th>\n",
       "      <td>buang air kecil</td>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3643</th>\n",
       "      <td>menarik napas penghabisan</td>\n",
       "      <td>-5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>minta kpd tuhan</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           word  weight  num_of_words\n",
       "3607         putus tali gantung      -2             3\n",
       "1925         jalan bebas hambat       2             3\n",
       "7468            buang air kecil      -3             3\n",
       "3643  menarik napas penghabisan      -5             3\n",
       "1902            minta kpd tuhan       3             3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_dict.to_csv('../dataset/wordlist/lexicon_dict_all.csv', index=False)\n",
    "\n",
    "lexicon_dict[lexicon_dict['num_of_words'] == 3].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = dict(zip(lexicon_dict['word'], lexicon_dict['weight']))\n",
    "vectorizer = CountVectorizer(vocabulary=lexicon.keys(), ngram_range=(1, 5))\n",
    "\n",
    "def detokenize(tokens):\n",
    "\treturn TreebankWordDetokenizer().detokenize(tokens)\n",
    "\n",
    "def determine_polarity(text):\n",
    "\tbow_matrix = vectorizer.fit_transform([text]).toarray()\n",
    "\t\n",
    "\tpolarity = 0\n",
    "\tfor word, score in zip(vectorizer.get_feature_names_out(), bow_matrix[0]):\n",
    "\t\tpolarity += lexicon[word] * score\n",
    "\treturn polarity\n",
    "\n",
    "def sentiment_analyze(polarity):\n",
    "\treturn 1 if polarity >= 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96cd6f140f943bb8fd6520abbe5e674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/7080 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8dc570b9e444915bf06e4d56a071f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/7080 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29dfc6b9ff24528a1681bd146354ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/7080 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1fb19d78944264a846f041c06d5240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/7080 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>tokens_ready</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@soeyoto1 @msaid_didu Bukti kalau Pemerintahan...</td>\n",
       "      <td>[bukti, perintah, pro, rakyat, pro, oligarki, ...</td>\n",
       "      <td>bukti perintah pro rakyat pro oligarki bbmnya ...</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@KompasTV Mentri esdm, trus patokanmu apa? Kan...</td>\n",
       "      <td>[menteri, esdm, patok, kantong, jebol, korupsi...</td>\n",
       "      <td>menteri esdm patok kantong jebol korupsi imbas...</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@hnurwahid Ngaku masih subsidi tapi ada swasta...</td>\n",
       "      <td>[subsidi, swasta, jual, murah, subsidi, pimpin...</td>\n",
       "      <td>subsidi swasta jual murah subsidi pimpin tukan...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Tan_Mar3M Kalau Vivo bisaberani bertahan deng...</td>\n",
       "      <td>[berani, tahan, harga, nasib]</td>\n",
       "      <td>berani tahan harga nasib</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Menteri BUMN Erick Thohir menegaskan persiapan...</td>\n",
       "      <td>[menteri, bumn, erick, thohir, indonesia, tran...</td>\n",
       "      <td>menteri bumn erick thohir indonesia transisi e...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  @soeyoto1 @msaid_didu Bukti kalau Pemerintahan...   \n",
       "1  @KompasTV Mentri esdm, trus patokanmu apa? Kan...   \n",
       "2  @hnurwahid Ngaku masih subsidi tapi ada swasta...   \n",
       "3  @Tan_Mar3M Kalau Vivo bisaberani bertahan deng...   \n",
       "4  Menteri BUMN Erick Thohir menegaskan persiapan...   \n",
       "\n",
       "                                        tokens_ready  \\\n",
       "0  [bukti, perintah, pro, rakyat, pro, oligarki, ...   \n",
       "1  [menteri, esdm, patok, kantong, jebol, korupsi...   \n",
       "2  [subsidi, swasta, jual, murah, subsidi, pimpin...   \n",
       "3                      [berani, tahan, harga, nasib]   \n",
       "4  [menteri, bumn, erick, thohir, indonesia, tran...   \n",
       "\n",
       "                                                text  polarity  sentiment  \n",
       "0  bukti perintah pro rakyat pro oligarki bbmnya ...        -2          0  \n",
       "1  menteri esdm patok kantong jebol korupsi imbas...        -9          0  \n",
       "2  subsidi swasta jual murah subsidi pimpin tukan...         6          1  \n",
       "3                           berani tahan harga nasib         4          1  \n",
       "4  menteri bumn erick thohir indonesia transisi e...         2          1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(processed_target_path, delimiter=';')\n",
    "\n",
    "df['tokens_ready'] = df['tokens_ready'].swifter.apply(literal_eval)\n",
    "df['text'] = df['tokens_ready'].swifter.apply(detokenize)\n",
    "df['polarity'] = df['text'].swifter.apply(determine_polarity)\n",
    "df['sentiment'] = df['polarity'].swifter.apply(sentiment_analyze)\n",
    "\n",
    "df.to_csv(output_path, index=False, header=True, sep=';')\n",
    "\n",
    "df[['content', 'tokens_ready', 'text', 'polarity', 'sentiment']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 15 2022, 18:25:35) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85fe51655c1fcaa9a7b9c0223583abd4e8b4409b0fbdb1dc760dec4edd874462"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
