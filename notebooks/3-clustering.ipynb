{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering: Data Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import swifter\n",
    "\n",
    "from ast import literal_eval\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "indoset_lexicon_neg_path = '../dataset/wordlist/indoset_lexicon_neg.csv'\n",
    "indoset_lexicon_pos_path = '../dataset/wordlist/indoset_lexicon_pos.csv'\n",
    "vulgarity_lexicon_path = '../dataset/wordlist/vulgarity_lexicon.csv'\n",
    "\n",
    "target = 'tweets.csv'\n",
    "processed_target_path = f'../dataset/processed/processed_{target}'\n",
    "output_path = f'../dataset/processed/supervised_{target}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lexicon neg: 6609\n",
      "Total lexicon pos: 3609\n",
      "Total lexicon vulgarity: 62\n"
     ]
    }
   ],
   "source": [
    "indoset_lexicon_neg = pd.read_csv(indoset_lexicon_neg_path, delimiter='\\t')\n",
    "indoset_lexicon_pos = pd.read_csv(indoset_lexicon_pos_path, delimiter='\\t')\n",
    "vulgarity_lexicon = pd.read_csv(vulgarity_lexicon_path, header=None, delimiter='\\t')\n",
    "\n",
    "print(f\"Total lexicon neg:\", len(indoset_lexicon_neg))\n",
    "print(f\"Total lexicon pos:\", len(indoset_lexicon_pos))\n",
    "print(f\"Total lexicon vulgarity:\", len(vulgarity_lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10280\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>rompok</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>belok</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5357</th>\n",
       "      <td>umpatan</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>berjasa</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9406</th>\n",
       "      <td>menggebos</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  weight\n",
       "3672     rompok      -2\n",
       "3433      belok       3\n",
       "5357    umpatan      -4\n",
       "2274    berjasa       4\n",
       "9406  menggebos      -5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_dict = pd.concat([indoset_lexicon_pos, indoset_lexicon_neg], ignore_index=True)\n",
    "\n",
    "vulgarity_lexicon_weight = [-5 for word in vulgarity_lexicon[0]]\n",
    "vulgarity_lexicon = pd.DataFrame(list(zip(vulgarity_lexicon[0],vulgarity_lexicon_weight)),columns =['word','weight'])\n",
    "\n",
    "lexicon_dict = pd.concat([lexicon_dict, vulgarity_lexicon], ignore_index=True)\n",
    "print(len(lexicon_dict))\n",
    "lexicon_dict.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_folding(text):\n",
    "    return text.lower()\n",
    "    \n",
    "def num_of_words(item):\n",
    "    words = word_tokenize(item['word'])\n",
    "    number = len(words)\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5a701993284b6db845c845dc49984d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da04acc0aed419d998f9d0edece9ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9109\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "      <th>num_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>draw</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>kemampuan</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5968</th>\n",
       "      <td>jengkang</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6875</th>\n",
       "      <td>langking</td>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7504</th>\n",
       "      <td>bekicot</td>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  weight  num_of_words\n",
       "8123       draw      -3             1\n",
       "2178  kemampuan       4             1\n",
       "5968   jengkang      -5             1\n",
       "6875   langking      -4             1\n",
       "7504    bekicot      -4             1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_dict['word'] = lexicon_dict['word'].swifter.apply(case_folding)\n",
    "lexicon_dict['num_of_words'] = lexicon_dict.swifter.apply(num_of_words, axis=1)\n",
    "lexicon_dict = lexicon_dict.drop(lexicon_dict[lexicon_dict['num_of_words'] == 0].index, axis=0)\n",
    "lexicon_dict.drop_duplicates(subset=['word'], keep='first',inplace=True)\n",
    "lexicon_dict = lexicon_dict.reset_index(drop=True)\n",
    "\n",
    "print(len(lexicon_dict))\n",
    "lexicon_dict.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "      <th>num_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>naik ke pelaminan</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7468</th>\n",
       "      <td>buang air kecil</td>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>jalan bebas hambat</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5344</th>\n",
       "      <td>tarik napas habis</td>\n",
       "      <td>-5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8684</th>\n",
       "      <td>cacing rambut kuda</td>\n",
       "      <td>-4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    word  weight  num_of_words\n",
       "1501   naik ke pelaminan       3             3\n",
       "7468     buang air kecil      -3             3\n",
       "1925  jalan bebas hambat       2             3\n",
       "5344   tarik napas habis      -5             3\n",
       "8684  cacing rambut kuda      -4             3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_dict.to_csv('../dataset/wordlist/lexicon_dict_all.csv', index=False)\n",
    "\n",
    "lexicon_dict[lexicon_dict['num_of_words'] == 3].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = dict(zip(lexicon_dict['word'], lexicon_dict['weight']))\n",
    "vectorizer = CountVectorizer(vocabulary=lexicon.keys(), ngram_range=(1, 5))\n",
    "\n",
    "def detokenize(tokens):\n",
    "\treturn TreebankWordDetokenizer().detokenize(tokens)\n",
    "\n",
    "def determine_polarity(text):\n",
    "\tbow_matrix = vectorizer.fit_transform([text]).toarray()\n",
    "\t\n",
    "\tpolarity = 0\n",
    "\tfor word, score in zip(vectorizer.get_feature_names_out(), bow_matrix[0]):\n",
    "\t\tpolarity += lexicon[word] * score\n",
    "\treturn polarity\n",
    "\n",
    "def sentiment_analyze(polarity):\n",
    "\treturn 1 if polarity >= 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e7ebf7ac064c6e8b6fde014418f6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/7104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3509ab3be4b64c798e6a3b551a2ebfc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/7104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11c3de697194e1090e3fb72a41afd68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/7104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce836d674813420eb8fbfab187933c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/7104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>tokens_ready</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@soeyoto1 @msaid_didu Bukti kalau Pemerintahan...</td>\n",
       "      <td>[bukti, perintah, pro, rakyat, pro, oligarki, ...</td>\n",
       "      <td>bukti perintah pro rakyat pro oligarki vivo bb...</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@KompasTV Mentri esdm, trus patokanmu apa? Kan...</td>\n",
       "      <td>[menteri, esdm, patok, kantong, pertamina, jeb...</td>\n",
       "      <td>menteri esdm patok kantong pertamina jebol kor...</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@hnurwahid Ngaku masih subsidi tapi ada swasta...</td>\n",
       "      <td>[aku, subsidi, swasta, jual, murah, subsidi, p...</td>\n",
       "      <td>aku subsidi swasta jual murah subsidi pertamin...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Tan_Mar3M Kalau Vivo bisaberani bertahan deng...</td>\n",
       "      <td>[vivo, berani, tahan, harga, nasib, pertamina]</td>\n",
       "      <td>vivo berani tahan harga nasib pertamina</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Menteri BUMN Erick Thohir menegaskan persiapan...</td>\n",
       "      <td>[menteri, bumn, erick, thohir, siap, indonesia...</td>\n",
       "      <td>menteri bumn erick thohir siap indonesia trans...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  @soeyoto1 @msaid_didu Bukti kalau Pemerintahan...   \n",
       "1  @KompasTV Mentri esdm, trus patokanmu apa? Kan...   \n",
       "2  @hnurwahid Ngaku masih subsidi tapi ada swasta...   \n",
       "3  @Tan_Mar3M Kalau Vivo bisaberani bertahan deng...   \n",
       "4  Menteri BUMN Erick Thohir menegaskan persiapan...   \n",
       "\n",
       "                                        tokens_ready  \\\n",
       "0  [bukti, perintah, pro, rakyat, pro, oligarki, ...   \n",
       "1  [menteri, esdm, patok, kantong, pertamina, jeb...   \n",
       "2  [aku, subsidi, swasta, jual, murah, subsidi, p...   \n",
       "3     [vivo, berani, tahan, harga, nasib, pertamina]   \n",
       "4  [menteri, bumn, erick, thohir, siap, indonesia...   \n",
       "\n",
       "                                                text  polarity  sentiment  \n",
       "0  bukti perintah pro rakyat pro oligarki vivo bb...        -2          0  \n",
       "1  menteri esdm patok kantong pertamina jebol kor...        -9          0  \n",
       "2  aku subsidi swasta jual murah subsidi pertamin...         8          1  \n",
       "3            vivo berani tahan harga nasib pertamina         4          1  \n",
       "4  menteri bumn erick thohir siap indonesia trans...         3          1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(processed_target_path, delimiter=';')\n",
    "\n",
    "df['tokens_ready'] = df['tokens_ready'].swifter.apply(literal_eval)\n",
    "df['text'] = df['tokens_ready'].swifter.apply(detokenize)\n",
    "df['polarity'] = df['text'].swifter.apply(determine_polarity)\n",
    "df['sentiment'] = df['polarity'].swifter.apply(sentiment_analyze)\n",
    "\n",
    "df.to_csv(output_path, index=False, header=True, sep=';')\n",
    "\n",
    "df[['content', 'tokens_ready', 'text', 'polarity', 'sentiment']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 15 2022, 18:25:35) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85fe51655c1fcaa9a7b9c0223583abd4e8b4409b0fbdb1dc760dec4edd874462"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
